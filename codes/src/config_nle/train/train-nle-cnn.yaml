# train:
network:
  seqC_net:
    type: cnn
    hidden_dim: 64
    lstm_layers: 3
    conv_filter_size: 3
  theta_net:
    hidden_dim: 64
    num_layers: 4
  cat_net:
    hidden_dim: 256

training:
  learning_rate         : 5e-5
  clip_max_norm         : 1e-5
  weight_decay          : 1e-9
  
  stop_after_epochs     : 1000

  min_num_epochs        : 5000
  max_num_epochs        : 2147483647
  
  warmup_epochs         : 20
  initial_lr            : 1e-8
  # scheduler             : 'ReduceLROnPlateau'
  # scheduler_params      : {'patience': 3, 'factor': 0.5, 'min_lr': 0}
  # scheduler             : 'CosineAnnealingWarmRestarts'
  # scheduler_params      : {'T_0': 7, 'T_mult': 2}
  scheduler             : 'None'
  scheduler_params      : {}
  
  print_freq            : 1000 # 2+1 records per epoch
  plot_time_interval_s  : 60
  # num_atoms             : 10
  # use_combined_loss     : True