pipeline_version: nle
log_dir: ./src/train_nle/logs/nle-test
data_path: /home/ubuntu/tmp/NSC/data/dataset-comb
seed: 100
debug: false
gpu: true
continue_from_checkpoint: ''
experiment_settings:
  chosen_dur_list:
  - 3
  - 5
  - 7
  - 9
  - 11
  - 13
  - 15
  chosen_MS_list:
  - 0.2
  - 0.4
  - 0.8
  seqC_sample_per_MS: 700
prior:
  num_prior_sample: 500
  prior_min:
  - -2.5
  - 0
  - 0
  - -11
  prior_max:
  - 2.5
  - 77
  - 18
  - 10
  prior_labels:
  - bias
  - sigma2a
  - sigma2s
  - L0
  normalize: true
  ignore_ss: false
x_o:
  trial_data_path: ../data/trials.mat
  subject_id: 2
simulator:
  model_name: B-G-L0S-O-N-
dataset:
  seqC_process: norm
  nan2num: -1
  summary_type: 0
  num_max_sets: 20
  num_max_theta_each_set: 500
  chosen_dur_list:
  - 3
  - 9
  - 15
  crop_dur: true
  permutation_mode: online
  num_probR_sample: 25
  batch_size: 61440
  pin_memory: true
  num_workers: 8
  prefetch_factor: 2
train:
  density_estimator:
    embedding_net:
      type: conv_lstm
      hidden_size: 1024
      output_size: 256
    posterior_nn:
      model: mdn
      hidden_features: 128
      num_transforms: 2
  training:
    learning_rate: 5.0e-05
    clip_max_norm: 1.0e-05
    weight_decay: 1.0e-09
    stop_after_epochs: 100
    min_num_epochs: 100
    max_num_epochs: 2147483647
    warmup_epochs: 5
    initial_lr: 1.0e-08
    scheduler: None
    scheduler_params: {}
    print_freq: 5
    num_atoms: 10
    use_combined_loss: true
  posterior:
    num_posterior_check: 2
    sampling_num: 2000
    step: 1
