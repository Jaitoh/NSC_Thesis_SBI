# dataset:

# ========== parameter settings for the seqC ==========
seqC_process: 'norm'
nan2num: -1
# seqC_process: 'summary'
summary_type: 0
# summary_type: 1  # 0: detailed information, 1: brief information

# # ========== parameter settings for the probR ==========
num_max_sets                : 101 #101 in total
num_max_theta_each_set      : 5000 #5000 in total

dataset_chosen_mode         : 'fixed' # determine how to choose all the dsets, theta
  # 'random': randomly choose the dsets, theta
  # 'fixed': choose the dsets, theta in a fixed order

test_fraction               : [10, 20, 30, 40]
test_num_theta              : 100
check_test_perf             : True

# train_dataset_mode          : 'increment' # determine how to choose the training dataset
  # 'whole': use all the data as one dataset, training once for all dsets
  # 'increment': append one more dataset at a time, training for each increased sized dset, limited to the last ndsets
increment_params            : {'init': 2 , 'step': 2, 'max_load': 10, 'loop': True, 'only_one_set': False}
  # increment_step: the dset for the increment
  # ndset_limit: the max dset size for the increment, -1 means no limit
  # loop: whether to loop over the dsets
train_num_theta             : 500
validation_fraction         : 0.1

chosen_dur_trained_in_sequence: 
  - [3, 9, 15]
crop_dur                    : True

# batch_process_method        : 'collate_fn'
# batch_size                  : 64
batch_process_method        : 'in_dataset'
batch_size                  : 128 #=32*100
permutation_mode            : 'random' # fixed, random
num_probR_sample            : 100 #25
shuffling_method            : 0 # 0: complex shuffling, 1: simple shuffling


num_workers                 : 4
pin_memory                  : True

use_data_prefetcher         : True # set to false when memory is not enough
prefetch_factor             : 1
Rchoice_method              : 'probR_sampling' # probR, probR_threshold