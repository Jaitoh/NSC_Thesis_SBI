train:
  inference:
    method: 'snpe'

  density_estimator:
    embedding_net: 
      type: lstm
      hidden_size: 64
      output_size: 32
    posterior_nn:
      model: maf
      hidden_features: 128
      num_transforms: 5
    

  training:
    
    stop_after_epochs     : 25
    stop_after_dsets      : 25
    max_num_epochs        : 2147483647
    max_num_dsets         : 2147483647

    print_freq            : 5 # 20 records per epoch

    learning_rate         : 1e-2
    scheduler             : 'ReduceLROnPlateau'
    scheduler_params      : {'patience': 5, 'factor': 0.5, 'min_lr': 1e-8}
    scheduler             : 'CosineAnnealingWarmRestarts'
    scheduler_params      : {'T_0': 15, 'T_mult': 2}
    # scheduler             : 'CosineAnnealingLR'
    # scheduler_params      : {'T_max': 10}

    clip_max_norm         : 4.0

    num_rounds            : 3
    num_runs              : 10
    num_atoms             : 10
    
  posterior:
    step          : 25     # the epoch steps to check posterior during training
    sampling_num  : 5000
    val_set_size  : 1