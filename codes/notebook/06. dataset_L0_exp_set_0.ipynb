{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- memory usage of processing sampling shuffle is *huge*\n",
    "    - subset processing\n",
    "    - using collate_fn during training\n",
    "- using summary feature as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_part_0.h5  dataset_part_0_snn.h5\n"
     ]
    }
   ],
   "source": [
    "# check dataset generated for experiment set 0 with model L0\n",
    "data_path = '../../data/dataset'\n",
    "!ls $data_path\n",
    "f1 = h5py.File(data_path + '/dataset_part_0.h5', 'r')\n",
    "f2 = h5py.File(data_path + '/dataset_part_0_snn.h5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<HDF5 dataset \"seqC\": shape (7, 3, 700, 15), type \"<f8\">,\n",
       " <HDF5 dataset \"theta\": shape (5000, 4), type \"<f4\">,\n",
       " <HDF5 dataset \"probR\": shape (7, 3, 700, 5000, 1), type \"<f8\">)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1['data']['seqC'], f1['data']['theta'], f1['data']['probR']\n",
    "f2['data']['seqC'], f2['data']['theta'], f2['data']['probR']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check if the two datasets are the same (using same seed on different machines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comparing snn and uzh generated datasets...\n",
      "seqC are the same\n",
      "theta are the same\n",
      "probR are the same\n"
     ]
    }
   ],
   "source": [
    "print('comparing snn and uzh generated datasets...')\n",
    "issame_seqC = not np.sum(np.nan_to_num(f1['data']['seqC'][:], -1)!=np.nan_to_num(f2['data']['seqC'][:], -1))\n",
    "issame_theta = not np.sum(np.nan_to_num(f1['data']['theta'][:], -1)!=np.nan_to_num(f2['data']['theta'][:], -1))\n",
    "issame_probR = not np.sum(np.nan_to_num(f1['data']['probR'][:], -1)!=np.nan_to_num(f2['data']['probR'][:], -1))\n",
    "print(\"seqC are the same\") if issame_seqC else print(\"!seqC are different!\")\n",
    "print(\"theta are the same\") if issame_theta else print(\"!theta are different!\")\n",
    "print(\"probR are the same\") if issame_probR else print(\"!probR are different!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1.close()\n",
    "f2.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge datasets into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list the files in the data directory using python\n",
    "data_dir = '../../data/dataset'\n",
    "files = [f for f in os.listdir(data_dir) if os.path.isfile(os.path.join(data_dir, f))]\n",
    "\n",
    "data_paths = []\n",
    "data_file_idxs = []\n",
    "for data_file in files:\n",
    "    data_path = f'{data_dir}/{data_file}'\n",
    "    data_paths.append(data_path)\n",
    "    # sort the data paths according to the file name\n",
    "    data_paths.sort(key=lambda x: x.split('_part_')[-1].split('.')[0])\n",
    "    data_file_idxs.append(int(data_path.split('_part_')[-1].split('.')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding ../../data/dataset/dataset_part_0.h5 to ../../data/dataset/dataset_L0_exp_set_0.h5\n",
      "adding ../../data/dataset/dataset_part_1.h5 to ../../data/dataset/dataset_L0_exp_set_0.h5\n",
      "\n",
      "merged file has keys: ['set_0', 'set_1']\n",
      "\n",
      "in one set_0 it has keys: ['probR', 'seqC', 'theta']\n",
      "seqC has a shape of: (7, 3, 700, 15)\n",
      "theta has a shape of: (5000, 4)\n",
      "probR has a shape of: (7, 3, 700, 5000, 1)\n"
     ]
    }
   ],
   "source": [
    "# create a new h5 file to store the combined dataset\n",
    "merged_data_path = f'{data_dir}/dataset_L0_exp_set_0.h5'\n",
    "\n",
    "with h5py.File(merged_data_path, 'w') as merged_data_file:\n",
    "    \n",
    "    for data_path, data_file_idx in zip(*(data_paths, data_file_idxs)):\n",
    "        print(f'adding {data_path} to {merged_data_path}')\n",
    "        data_file = h5py.File(data_path, 'r')\n",
    "        # copy the data group from the data file to the merged data file\n",
    "        set_group = merged_data_file.create_group(f'set_{data_file_idx}')\n",
    "        data_file.copy('data/seqC', set_group)\n",
    "        data_file.copy('data/probR', set_group)\n",
    "        data_file.copy('data/theta', set_group)\n",
    "        data_file.close()\n",
    "        merged_data_file.flush()\n",
    "\n",
    "    print(f'\\nmerged file has keys: {list(merged_data_file.keys())}')    \n",
    "    print(f\"\\nin one set_0 it has keys: {list(merged_data_file['set_0'].keys())}\")\n",
    "    print(f\"seqC has a shape of: {merged_data_file['set_0']['seqC'].shape}\")\n",
    "    print(f\"theta has a shape of: {merged_data_file['set_0']['theta'].shape}\")\n",
    "    print(f\"probR has a shape of: {merged_data_file['set_0']['probR'].shape}\")\n",
    "\n",
    "# merged_data_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
